{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Neural Dense Non-Rigid Structure from Motion with Latent Space Constraints [1]\n",
    "\n",
    "## ECCV 2020\n",
    "<center><img src=\"NRSfM_figs/title.png\" width=1000px alt=\"default\"/></center>\n",
    "\n",
    "[1] Sidhu, Vikramjit, et al. \"Neural dense non-rigid structure from motion with latent space constraints.\" Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XVI 16. Springer International Publishing, 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Non-rigid Structure from Motion \n",
    "\n",
    "Rigid structure-from-motion (SfM): assumes the object maintains a consistent shape (rigid body)\n",
    "\n",
    "Non-rigid Structure from Motion (NRSfM) deals with objects that can deform or change shape over time, such as human faces, animals, and other flexible objects.\n",
    "\n",
    "<center><img src=\"NRSfM_figs/example_nrsfm.png\" width=1000px alt=\"default\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Workflow: SfM\n",
    "\n",
    "<!-- $\\color{#EF5645}{\\text{Given:}}$ Image points $x_{ij}$ representing $X_j$ in camera $i$ with projection matrix $M_i$: \n",
    "\n",
    "After data centering: $\\hat x_{ij} = A_i \\hat X_j$, where we do not know $A_i$ and $\\hat X_j$.\n",
    "\n",
    "Goal: Factor out $A_i$ and $\\hat X_j$, for all $i$ and $j$.\n",
    "\n",
    "$$D = \\begin{bmatrix}\n",
    "A_1 \\hat X_1 & A_1 \\hat X_2 & ... & A_1 \\hat X_n\\\\\n",
    "A_2 \\hat X_1 & A_2 \\hat X_2 & ... & A_2 \\hat X_n\\\\\n",
    "... &  ... & ... & ...\\\\\n",
    "A_m \\hat X_1 & A_m \\hat X_2 & ... & A_m \\hat X_n\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "which we write: -->\n",
    "\n",
    "Consider a set of P points densely tracked across T frames\n",
    "- Measurement: 2D position of p-th point in image t: $\\textbf{w}_t^p=\\hat{\\textbf{w}}_t^p = \\textbf{t}_t$, centered by camera translation $\\textbf{t}_t$\n",
    "- Reconstruction: 3D coordinates of p-th point in image t $\\mathbf{s}_t^p=[x_t^p, y_t^p, z_t^p]^T$\n",
    "\n",
    "We build a linear system to map the 3D-to-2D point coordinates as:\n",
    "\n",
    "<center><img src=\"NRSfM_figs/WRS.png\" width=500px alt=\"default\"/></center>\n",
    "\n",
    "Note: in previous slides, we wrote it as: $D = MS$\n",
    "\n",
    "$D$->$W$: Measurement matrix, $M$->$R$: motion matrix $S$: structure (shape) matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Workflow: Non-rigid SfM:\n",
    "\n",
    "<center><img src=\"NRSfM_figs/workflow.png\" width=500px alt=\"default\"/></center>\n",
    "\n",
    "**Shape Representation for Non-rigid objects**:\n",
    "\n",
    "The 3D shape $(\\mathbf{S}_t)$ at time $(t)$ is often represented as:\n",
    "$$\n",
    "[\n",
    "\\mathbf{S}_t = \\mathbf{\\bar{S}} + \\sum_{i=1}^k c_{it} \\mathbf{B}_i\n",
    "]\n",
    "$$\n",
    "where $(\\mathbf{\\bar{S}})$ is the mean shape, $(\\mathbf{B}_i)$ are the basis shapes, $(c_{it})$ are the deformation coefficients at time $(t)$, and $(k)$ is the number of basis shapes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Workflow: Non-rigid SfM:\n",
    "\n",
    "<center><img src=\"NRSfM_figs/workflow.png\" width=500px alt=\"default\"/></center>\n",
    "\n",
    "   - **Mean Shape and Deformations**: \n",
    "      - The 3D shape of a non-rigid object at any given time can be thought of as a deviation from a mean shape. This is often represented using a linear combination of basis shapes.\n",
    "   - **Basis Shapes**: \n",
    "      - A set of shapes that, when combined, can approximate the deformations of the object. \n",
    "      - Typically learned from training data or through optimization techniques.\n",
    "\n",
    "The core component of NRSfM is a carefully designed deformation model with handcrafted priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Contributions\n",
    "\n",
    "<center><img src=\"NRSfM_figs/overview.png\" width=1000px alt=\"default\"/></center>\n",
    "\n",
    "This work embraces a diﬀerent formulation that can regress the deformation modes in a unsupervised manner during a neural network training\n",
    "\n",
    "- Core contribution: a new neural deformation model component based on auto-encoder\n",
    "    - Fully diﬀerentiable dense neural NRSfM approach.\n",
    "    - Encode priors in energy function to enhance the reconstruction accuracy\n",
    "- Extensive experimental evaluation & Several applications of the deformation model including \n",
    "    - shape compression, interpolation and completion\n",
    "    - fast direct non-rigid 3D reconstruction from monocular image sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Method Overview\n",
    "<center><img src=\"NRSfM_figs/method_overview_1.png\" width=500px alt=\"default\"/></center>\n",
    "\n",
    "<center><img src=\"NRSfM_figs/method_overview.png\" width=500px alt=\"default\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Modelling Leanable Deformation with Neural Networks\n",
    "\n",
    "<center><img src=\"NRSfM_figs/method_overview.png\" width=500px alt=\"default\"/></center>\n",
    "\n",
    "<!-- Non-rigid shape representation:\n",
    "$$\n",
    "[\n",
    "\\mathbf{S}_t = \\mathbf{\\bar{S}} + \\sum_{i=1}^k c_{it} \\mathbf{B}_i\n",
    "]\n",
    "$$ -->\n",
    "\n",
    "In this work:\n",
    "\n",
    "- Deformation autodecoder $f_{\\mathbf{\\theta}}$: \n",
    "    - $f_{\\mathbf{\\theta}}$ is a function of the latent space $\\mathbf{z}_t$, with nine fully-connected layers\n",
    "    <!-- - the weight matrix of the ﬁnal fully-connected layer of $f_{\\mathbf{\\theta}}$ can be interpreted as a low-rank linear subspace where every vector denotes a 3D displacement from the mean shape. -->\n",
    "    \n",
    "- Relate to shape space: $\\mathbf{S}_t=\\overline{\\mathbf{S}}+f_{\\boldsymbol{\\theta}}\\left(\\mathbf{z}_t\\right)$\n",
    "    - Both $\\overline{\\mathbf{S}}$ and $\\mathbf{R}_t$ are initialized by rigid factorization from $\\mathbf{W}$ (Tomasi-Kanade factorization method)\n",
    "    - the output can be interpreted as an analogue to the number of basis shapes in linear subspace models. $f_{\\boldsymbol{\\theta}}\\left(\\mathbf{z}_t\\right) -> \\sum_{i=1}^k c_{it} \\mathbf{B}_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Differentiable Energy (Loss) Function\n",
    "\n",
    "<center><img src=\"NRSfM_figs/energy_function.png\" width=600px alt=\"default\"/></center>\n",
    "\n",
    "- $\\mathbf{E}_{data}$: penalize the image re-projection errors\n",
    "\n",
    "    - $\\mathbf{E}_{\\text {data }}(\\boldsymbol{\\theta}, \\mathbf{z}, \\mathbf{R})=\\left\\|\\mathbf{W}-\\mathbf{R}\\left(\\left(\\mathbf{1}_T \\otimes \\overline{\\mathbf{S}}\\right)+f_{\\boldsymbol{\\theta}}(\\mathbf{z})\\right)\\right\\|_\\epsilon$\n",
    "\n",
    "- $\\mathbf{E}_{temp}$, $\\mathbf{E}_{spat}$, $\\mathbf{E}_{traj}$, $\\mathbf{E}_{latent}$: encode priors by soft (diffentiable) regularizations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Temporal & Trajectory Regularization\n",
    "\n",
    "<center><img src=\"NRSfM_figs/temporal_regularization.png\" width=500px alt=\"default\"/></center>\n",
    "\n",
    "$\\mathbf{E}_{temp}$: enforces temporal-preserving regularisation of the 3D shape via its latent space\n",
    "\n",
    "$\\mathbf{E}_{traj}$: imposes a subspace constraint on point trajectories throughout the whole sequence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Spatial Regularization\n",
    "\n",
    "<center><img src=\"NRSfM_figs/spatial_regularization&apos;.png\" width=500px alt=\"default\"/></center>\n",
    "\n",
    "$\\mathbf{E}_{spat}$: spatial-preserving regularisation for a neighbourhood. \n",
    "\n",
    "For dense observations, where most of the points in a local neighbourhood can follow a similar motion pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Latent Space Constraints\n",
    "\n",
    "$\\mathbf{E}_{latent}(\\mathbf{z})=\\| \\mathcal{F}(\\mathbf{z}) \\|_1$: \n",
    "$\\mathcal{F}()$ denotes Fourier transform operator\n",
    "\n",
    "- Imposes sparsity constraints over the latent vector by encouraging the sparsity of the Fourier series and removing less relevant frequency components.\n",
    "- Period Detection: The period of the sequence can be recovered by extracting the dominant frequency\n",
    "- Sequence Segmentation: The latent space is temporally segmented. Similar values are decoded into similar shapes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Experiments\n",
    "\n",
    "### Kinect paper\n",
    "<center><img src=\"NRSfM_figs/exp_paper.png\" width=500px alt=\"default\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Synthetic Face Sequences\n",
    "\n",
    "<center><img src=\"NRSfM_figs/exp_face.png\" width=500px alt=\"default\"/></center>\n",
    "\n",
    "<center><img src=\"NRSfM_figs/exp_face_2.png\" width=500px alt=\"default\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Kinect paper\n",
    "<center><img src=\"NRSfM_figs/exp_paper_2.png\" width=500px alt=\"default\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Effect of spatial constraints\n",
    "\n",
    "<center><img src=\"NRSfM_figs/exp_spatial.png\" width=500px alt=\"default\"/></center>\n",
    "\n",
    "<center><img src=\"NRSfM_figs/exp_spatial_2.png\" width=500px alt=\"default\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Effect of latent constaints\n",
    "\n",
    "<center><img src=\"NRSfM_figs/exp_latent_training.png\" width=500px alt=\"default\"/></center>\n",
    "\n",
    "<center><img src=\"NRSfM_figs/exp_latent.png\" width=500px alt=\"default\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Applications\n",
    "\n",
    "### Shape Compression, Interpolation, Denoising and Completion.\n",
    "\n",
    "<center><img src=\"NRSfM_figs/app_denoising.png\" width=500px alt=\"default\"/></center>\n",
    "\n",
    "<center><img src=\"NRSfM_figs/app_completion.png\" width=500px alt=\"default\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Direct Monocular Non-rigid 3D Reconstruction with Occlusion Handling.\n",
    "\n",
    "<center><img src=\"NRSfM_figs/app_reconstruction.png\" width=500px alt=\"default\"/></center>\n",
    "\n",
    "<center><img src=\"NRSfM_figs/app_reconstruction_2.png\" width=500px alt=\"default\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Remarks:\n",
    "\n",
    "- This paper introduced a neural-based non-rigid structure-of-motion\n",
    "    - Neural network (implicit):\n",
    "        - Deep features, implicit but powerful & robust\n",
    "        - Nonlinearity, with learnability\n",
    "    - Image Processing: \n",
    "        - SfM workflow stemming from factorization methods\n",
    "        - encode priors into regularization terms in energy (loss) function\n",
    "\n",
    "The good combination of neural-based learning methods (e.g., extract deep features, model implicit relations) and \"traditional\" image processing skills/priors contribute to further improvements.\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
