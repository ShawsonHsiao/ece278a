{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76b67dce",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center>Active and Volumetric Stereo</center>\n",
    "#### <center>Presented by: Maxwell Jung</center>\n",
    "\n",
    "Captured Image                                      | 3D Reconstruction\n",
    ":--------------------------------------------------:|:-------------------------:\n",
    "<img src=\"img/hand_fist_pattern.jpg\" alt=\"hand_fist_pattern\" width=\"500\"/> | <img src=\"img/hand_fist_polygon.gif\" alt=\"hand_fist_polygon\" width=\"500\"/>\n",
    "\n",
    "Source: [Rapid Shape Acquisition Using Color Structured Light and Multi-pass Dynamic Programming](https://grail.cs.washington.edu/projects/moscan/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c0b2b5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Agenda\n",
    "\n",
    "1. Introduce Active Stereo\n",
    "    1. Point method\n",
    "    2. Line method\n",
    "    3. Pattern method\n",
    "2. Demo Active Stereo\n",
    "3. Introduce Volumetric Stereo\n",
    "    1. Space Carving\n",
    "    2. Shadow Carving\n",
    "    3. Voxel Coloring\n",
    "4. Demo Volumetric Stereo\n",
    "5. Recent papers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7c97ab",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Examples\n",
    "\n",
    "Captured Image (line method)                        | 3D Reconstruction\n",
    ":--------------------------------------------------:|:-------------------------:\n",
    "<img src=\"img/digitalmichelangelo.jpg\" alt=\"digitalmichelangelo\" width=\"500\"/> | <img src=\"img/david3d.jpg\" alt=\"david3d\" width=\"500\"/>\n",
    "\n",
    "Source: [The Digital Michaelangelo project](https://accademia.stanford.edu/mich/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9af1f04",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Examples - cont.\n",
    "\n",
    "Captured Image (pattern method)                       | 3D Reconstruction\n",
    ":--------------------------------------------------:|:-------------------------:\n",
    "<img src=\"img/speckle-a.png\" alt=\"speckle-a\" width=\"500\"/> | <img src=\"img/speckle-b.png\" alt=\"speckle-b\" width=\"500\"/>\n",
    "\n",
    "Source: [Rapid Shape Acquisition Using Color Structured Light and Multi-pass Dynamic Programming](https://grail.cs.washington.edu/projects/moscan/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b6e9c2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Examples - cont.\n",
    "\n",
    "Captured Images (Space Carving)                       | 3D Reconstruction\n",
    ":--------------------------------------------------:|:-------------------------:\n",
    "<img src=\"img/space-carving-hands.jpeg\" alt=\"space-carving-hands\" width=\"500\"/> | <img src=\"img/space-carving-hands-result.png\" alt=\"space-carving-hands-result\" width=\"500\"/>\n",
    "\n",
    "Source: [A Theory of Shape by Space Carving](https://www.cs.toronto.edu/~kyros/pubs/00.ijcv.carve.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561c48d8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Traditional Stereo - Triangulation\n",
    "\n",
    "Given\n",
    "  - Pixels $p$ and $p'$ corresponding to the same 3D point $P$\n",
    "  - Calibrated Cameras (intrisic and extrinsic properties are known)\n",
    "\n",
    "Outcome\n",
    "  - Location of point $P$\n",
    "\n",
    "<img src=\"img/traditional-stereo.png\" alt=\"traditional-stereo\" width=\"600\"/>\n",
    "\n",
    "<center>Source: <a href=\"https://cvgl.stanford.edu/teaching/cs231a_winter1415/lecture/lecture8_volumetric_stereo.pdf\">Stanford CS231A lecture 8</a></center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ccc6d4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Traditional Stereo - Correspondence Problem\n",
    "\n",
    "How to ensure pixels $p$ and $p'$ **correspond** to the same 3D point $P$?\n",
    "\n",
    "Easy for humans, very difficult for computers - Sparse vs Dense correspondence\n",
    "\n",
    "<img src=\"img/correspondence.png\" alt=\"correspondence\" width=\"1000\"/>\n",
    "\n",
    "<center>Source: <a href=\"https://srs.amsi.org.au/student-blog/what-is-dense-correspondence/\">SRS - What is Dense Correspondence?</a></center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ef60ac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Solution: Active Stereo (Point)\n",
    "\n",
    "- Physically mark the object with an identifiable dot\n",
    "    - Replace camera and image plane with projector and projector virtual plane\n",
    "- Reconstruction\n",
    "    1. Span the dot across the surface of the object\n",
    "    2. Calculate coordinate of each dot using triangulation\n",
    "\n",
    "<img src=\"img/active-point.png\" alt=\"active-point\" width=\"600\"/>\n",
    "\n",
    "<center>Source: <a href=\"https://cvgl.stanford.edu/teaching/cs231a_winter1415/lecture/lecture8_volumetric_stereo.pdf\">Stanford CS231A lecture 8</a></center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6609509c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Active Stereo (Line)\n",
    "\n",
    "- Extension of the Active Stereo Point method\n",
    "    - Analogous to projecting multiple dots in a series simultaneously\n",
    "- Reconstruction\n",
    "    1. Scan line across the surface of the object\n",
    "    2. Calculate coordinates of each line using triangulation\n",
    "\n",
    "<img src=\"img/active-line.png\" alt=\"active-line\" width=\"600\"/>\n",
    "\n",
    "<center>Source: <a href=\"https://cvgl.stanford.edu/teaching/cs231a_winter1415/lecture/lecture8_volumetric_stereo.pdf\">Stanford CS231A lecture 8</a></center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c25e508",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Active Stereo (Line) - Example\n",
    "\n",
    "Laser Scanning                        | 3D Reconstruction\n",
    ":--------------------------------------------------:|:-------------------------:\n",
    "<img src=\"img/digitalmichelangelo.jpg\" alt=\"digitalmichelangelo\" width=\"500\"/> | <img src=\"img/david3d.jpg\" alt=\"david3d\" width=\"500\"/>\n",
    "\n",
    "Source: [The Digital Michaelangelo project](https://accademia.stanford.edu/mich/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b104b0e7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Active Stereo (Pattern)\n",
    "\n",
    "- Extension of the Active Stereo Point method\n",
    "    - Project multiple dots/lines covering a wide area\n",
    "- Reconstruction\n",
    "    1. Calculate coordinates of each dot/line using triangulation\n",
    "    2. Generate mesh from point cloud\n",
    "\n",
    "<img src=\"img/active-pattern.png\" alt=\"active-pattern\" width=\"600\"/>\n",
    "\n",
    "<center>Source: <a href=\"https://cvgl.stanford.edu/teaching/cs231a_winter1415/lecture/lecture8_volumetric_stereo.pdf\">Stanford CS231A lecture 8</a></center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c060940",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Active Stereo (Pattern) - Example\n",
    "\n",
    "- Microsoft Kinect for Xbox\n",
    "- Project pattern of infrared dots\n",
    "    - works well under any ambient light conditions\n",
    "\n",
    "<img src=\"img/kinect.png\" alt=\"kinect\" width=\"600\"/>\n",
    "\n",
    "<center>Source: <a href=\"https://www.mdpi.com/2220-9964/6/11/349\">A Post-Rectification Approach of Depth Images of Kinect v2 for 3D Reconstruction of Indoor Scenes</a></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27924953",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Active Stereo Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79a99ec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Volumetric Stereo\n",
    "\n",
    "- Work backwards from the 3D point to the individual projections\n",
    "    - Assume point $P$ is from the enclosed object\n",
    "    - Calculate the expected projection of $P$ for each camera\n",
    "    - Check if the expected projection matches the actual projection (**consistency check**)\n",
    "    - Mark $P$ as part of the object\n",
    "\n",
    "<img src=\"img/vstereo.png\" alt=\"vstereo\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb45e46",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Volumetric Stereo - Consistency Check\n",
    "\n",
    "- Space Carving\n",
    "    - Check if silhouettes match\n",
    "- Shadow Carving\n",
    "    - Check if shadows match\n",
    "- Voxel Coloring\n",
    "    - Check if colors match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6ab192",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Space Carving - Intuition\n",
    "\n",
    "- Silhouettes provide useful 3D information\n",
    "\n",
    "Silhouette | Object\n",
    ":--------------------------------------------------:|:-------------------------:\n",
    "<img src=\"img/toy-dino-silhouette.png\" alt=\"toy-dino-silhouette\" width=\"500\"/> | <img src=\"img/toy-dino.png\" alt=\"toy-dino\" width=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f68f90",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Space Carving - Visual Cone\n",
    "\n",
    "- Create a cone from the camera origin to infinity using the silhouette\n",
    "- Represents the set of points that map to the observed silhouette\n",
    "\n",
    "<img src=\"img/silhouette-cone.png\" alt=\"silhouette-cone\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f486d56",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Space Carving - Visual Hull\n",
    "\n",
    "- Intersection of all Visual Cones\n",
    "- Represents the set of points that map to **all** the observed silhouettes\n",
    "\n",
    "<img src=\"img/visual-hull.png\" alt=\"visual-hull\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b349c941",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Space Carving - Voxels\n",
    "\n",
    "- 3D version of a pixel\n",
    "\n",
    "<img src=\"img/voxel.png\" alt=\"voxel\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4ee46f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Space Carving - Voxel Implementation\n",
    "\n",
    "- Iterate over each voxel and check if each voxel is inside the Visual Hull\n",
    "    - $O(n^3)$ time complexity\n",
    "        - Use Octrees for complexity reduction\n",
    "\n",
    "<img src=\"img/voxel-carving.png\" alt=\"voxel-carving\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c3e9e6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Space Carving - Limitations\n",
    "\n",
    "- Need a lot of silhouettes for high accuracy\n",
    "- Impossible to detect concavitiy\n",
    "\n",
    "<img src=\"img/concavity.png\" alt=\"concavity\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfc025a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Shadow Carving - Intuition\n",
    "\n",
    "- Concave surfaces often cast shadows onto itself\n",
    "    - Augment Space Carving with shadows to estimate concavity\n",
    "\n",
    "<img src=\"img/crater.png\" alt=\"crater\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffd3621",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Shadow Carving - Setup\n",
    "\n",
    "- Take multiple photos with different lighting conditions\n",
    "    - One light source per photo\n",
    "\n",
    "<img src=\"img/shadow-carving-setup.png\" alt=\"shadow-carving-setup\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eb3286",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Shadow Carving - Voxel Implementation\n",
    "\n",
    "1. Obtain upper bound estimate using Space Carving\n",
    "2. Project shadow onto virtual light image\n",
    "3. Remove voxels that project to both image shadow and virtual image shadow\n",
    "- $O((k+1)n^3)$ time complexity for $k$ lights and $n \\times n \\times n$ voxel resolution\n",
    "\n",
    "<img src=\"img/shadow-carving.png\" alt=\"shadow-carving\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906f245c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Shadow Carving (vs. Space Carving)\n",
    "\n",
    "<img src=\"img/space-vs-shadow.png\" alt=\"space-vs-shadow\" width=\"600\"/>\n",
    "<img src=\"img/space-vs-shadow2.png\" alt=\"space-vs-shadow2\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b34de2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Voxel Coloring\n",
    "- Check if the color of voxels sufficiently match between projections\n",
    "- Advantage\n",
    "    - colored 3D reconstruction\n",
    "- Disadvantage\n",
    "    - cannot guarantee unique solution\n",
    "    - requires Lambertian surface (luminance does not change with viewpoint)\n",
    "\n",
    "<img src=\"img/voxel-coloring.png\" alt=\"voxel-coloring\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670f3ac4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Voxel Coloring - Ambiguity\n",
    "\n",
    "- Different 3D reconstructions can produce the same 2D projections\n",
    "- solution: visibility constraint\n",
    "    - traverse voxels layer by layer starting from one closest to camera\n",
    "    - ensure voxel is viewable by at least 2 cameras\n",
    "\n",
    "<img src=\"img/voxel-coloring-ambig.png\" alt=\"voxel-coloring-ambig\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eded50",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Voxel Coloring - Results\n",
    "\n",
    "Input | Voxel Coloring Output\n",
    ":--------------------------------------------------:|:-------------------------:\n",
    "<img src=\"img/dino.gif\" alt=\"dino\" width=\"500\"/> | <img src=\"img/dino-3d.gif\" alt=\"dino-3d\" width=\"500\"/>\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
